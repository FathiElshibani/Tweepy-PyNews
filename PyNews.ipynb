{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f86c0f9f0701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Dependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Twitter API Keys\n",
    "consumer_key = \"YOUR CONSUMER KEY\" \n",
    "consumer_secret = \"YOUR CONSUMER SECRET\"\n",
    "access_token = \"YOUR TOKEN\"\n",
    "access_token_secret = \"YOUR TOKEN SECRET\"\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Target News Account\n",
    "target_users = [\"@BBCNews\", \"@CBS\", \"@CNN\", \"@FoxNews\",\"@nytimes\"]\n",
    "\n",
    "# List to hold Target News sentiments results\n",
    "results_list = []\n",
    "\n",
    "# Loop through all target News Accounts on Twitter\n",
    "for target_user in target_users:\n",
    "    \n",
    "    # Variables for holding sentiments for target News Accounts\n",
    "    compound_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    neutral_list = []\n",
    "\n",
    "    # Variable for max_id\n",
    "    oldest_tweet = None\n",
    "\n",
    "    # Loop through 5 pages of tweets (total 100 tweets)\n",
    "    for x in range(5):\n",
    "\n",
    "        # Get all tweets from home feed\n",
    "        public_tweets = api.user_timeline(target_user, max_id = oldest_tweet, page=x)\n",
    "        \n",
    "        # Loop through all tweets \n",
    "        for tweet in public_tweets:\n",
    "\n",
    "            # Run Vader Analysis on each tweet\n",
    "            results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "            compound = results[\"compound\"]\n",
    "            pos = results[\"pos\"]\n",
    "            neu = results[\"neu\"]\n",
    "            neg = results[\"neg\"]\n",
    "            \n",
    "            # Add each value to the appropriate list\n",
    "            compound_list.append(compound)\n",
    "            positive_list.append(pos)\n",
    "            negative_list.append(neg)\n",
    "            neutral_list.append(neu)\n",
    "\n",
    "            # Get Tweet ID, subtract 1, and assign to oldest_tweet\n",
    "            oldest_tweet = tweet['id'] - 1\n",
    "\n",
    "    \n",
    "            # Store the Average Sentiments for all target News Accounts\n",
    "            sentiment = {\"User\": target_user,\n",
    "                \"Compound\": np.mean(compound_list),\n",
    "                \"Positive\": np.mean(positive_list),\n",
    "                \"Neutral\": np.mean(negative_list),\n",
    "                \"Negative\": np.mean(neutral_list),\n",
    "                \"Tweet Count\": len(compound_list)}\n",
    "\n",
    "\n",
    "    # Append target News results to 'results_list'\n",
    "    results_list.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert target News sentiments to DataFrame\n",
    "sentiments_pd = pd.DataFrame(results_list).round(3)\n",
    "sentiments_pd.head()\n",
    "sentiments_pd.to_csv('sentimentsNews_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Overall Media Sentiment based on Twitter Bar Graph\n",
    "\n",
    "plt.bar(sentiments_pd[\"User\"], sentiments_pd[\"Compound\"], label = sentiments_pd[\"Compound\"], color='r', alpha=0.5, align=\"edge\")\n",
    "\n",
    "# Adding the required limit, style, title, legend, and text\n",
    "plt.xlim(0, len(sentiments_pd[\"User\"]))\n",
    "plt.ylim(min(sentiments_pd[\"Compound\"])-0.1, max(sentiments_pd[\"Compound\"])+0.1)\n",
    "plt.title(\"Overall Media Sentiment based on Twitter\" , fontsize= 14)\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "mpl.style.use(\"seaborn\")\n",
    "plt.savefig(\"BarChart.png\")\n",
    "\n",
    "#display the final plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Collect the required fata for Sentiment Analysis of Media Tweets Plot\n",
    "\n",
    "# Variables for holding sentiments\n",
    "sentiments2 = []\n",
    "\n",
    "# Loop through all target News Accounts on Twitter\n",
    "for target_user in target_users:\n",
    "    \n",
    "    # Counter\n",
    "    counter = 1\n",
    "    \n",
    "    # Variable for max_id\n",
    "    oldest_tweet = None\n",
    "    \n",
    "    # Variables for holding sentiments for target News Accounts\n",
    "    compound_list2 = []\n",
    "    positive_list2 = []\n",
    "    negative_list2 = []\n",
    "    neutral_list2 = []\n",
    " \n",
    "\n",
    "    # Loop through 5 pages of tweets (total 100 tweets)\n",
    "    for x in range(5):\n",
    "\n",
    "        # Get all tweets from home feed\n",
    "        public_tweets = api.user_timeline(target_user, max_id = oldest_tweet, page=x)\n",
    "        \n",
    "        # Loop through all tweets \n",
    "        for tweet in public_tweets:\n",
    "\n",
    "            # Run Vader Analysis on each tweet\n",
    "            results2 = analyzer.polarity_scores(tweet[\"text\"])\n",
    "            compound = results2[\"compound\"]\n",
    "            pos = results2[\"pos\"]\n",
    "            neu = results2[\"neu\"]\n",
    "            neg = results2[\"neg\"]\n",
    "            tweets_ago = counter\n",
    "            \n",
    "            # Add each value to the appropriate list\n",
    "            compound_list2.append(compound)\n",
    "            positive_list2.append(pos)\n",
    "            negative_list2.append(neg)\n",
    "            neutral_list2.append(neu)\n",
    "\n",
    "            # Get Tweet ID, subtract 1, and assign to oldest_tweet\n",
    "            oldest_tweet = tweet['id'] - 1\n",
    "\n",
    "    \n",
    "            # Add sentiments for each tweet into a list\n",
    "            sentiments2.append({\"User\": target_user,\n",
    "                           \"Date\": tweet[\"created_at\"], \n",
    "                           \"Compound\": compound,\n",
    "                           \"Positive\": pos,\n",
    "                           \"Negative\": neu,\n",
    "                           \"Neutral\": neg,\n",
    "                           \"Tweets Ago\": counter})\n",
    "        \n",
    "            # Add to counter \n",
    "            counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert target News sentiments to DataFrame\n",
    "sentiments_pd2 = pd.DataFrame(sentiments2).round(3)\n",
    "sentiments_pd2.head()\n",
    "sentiments_pd2.to_csv('sentimentsNews_details.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Sentiment Analysis of Media Tweets Plot\n",
    "\n",
    "# Create data frames based on News Name\n",
    "nytimesData = sentiments_pd2.loc[(sentiments_pd2[\"User\"] == \"@nytimes\"),:]\n",
    "CNNData = sentiments_pd2.loc[(sentiments_pd2[\"User\"] == \"@CNN\"),:]\n",
    "BBCData = sentiments_pd2.loc[(sentiments_pd2[\"User\"] == \"@BBCNews\"),:]\n",
    "CBSData = sentiments_pd2.loc[(sentiments_pd2[\"User\"] == \"@CBS\"),:]\n",
    "FoxData = sentiments_pd2.loc[(sentiments_pd2[\"User\"] == \"@FoxNews\"),:]\n",
    "\n",
    "# plotting 5 scatter plots based on News Name\n",
    "plt.scatter(x= nytimesData[\"Tweets Ago\"], y= nytimesData[\"Compound\"],label= \"New York Times\",\n",
    "            c=\"yellow\", edgecolor='black', lw=1, alpha=0.8)\n",
    "plt.scatter(x= CNNData[\"Tweets Ago\"], y= CNNData[\"Compound\"],label= \"CNN\",\n",
    "            c=\"red\", edgecolor='black', lw=1, alpha=0.8)\n",
    "plt.scatter(x= BBCData[\"Tweets Ago\"], y= BBCData[\"Compound\"],label= \"BBC\",\n",
    "            c=\"lightcoral\", edgecolor='black', lw=1, alpha=0.8)\n",
    "plt.scatter(x= CBSData[\"Tweets Ago\"], y= CBSData[\"Compound\"],label= \"CBS\",\n",
    "            c=\"green\", edgecolor='black', lw=1, alpha=0.8) \n",
    "plt.scatter(x= FoxData[\"Tweets Ago\"], y= FoxData[\"Compound\"],label= \"Fox\",\n",
    "            c=\"blue\", edgecolor='black', lw=1, alpha=0.8)\n",
    "\n",
    "# Adding the required limit, style, title, legend, and text\n",
    "plt.xlim(100, 0)\n",
    "plt.ylim(-1,1)\n",
    "plt.title(\"Sentiment Analysis of Media Tweets\" , fontsize= 14)\n",
    "plt.xlabel(\"Tweet Ago\")\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "plt.legend(title= \"Media Sources\",loc='upper left', prop={'size':6}, bbox_to_anchor=(1,1) )\n",
    "mpl.style.use(\"seaborn\")\n",
    "plt.savefig(\"ScatterChart.png\")\n",
    "\n",
    "#display the final plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
